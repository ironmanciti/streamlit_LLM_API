from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file
#------------------------------------------------------------

import streamlit as st
from langchain.prompts import PromptTemplate
from langchain.llms import CTransformers
from langchain.llms import OpenAI

#Function to get the response back
def getLLMResponse(form_input, email_sender, email_recipient, email_style):
    #llm = OpenAI(temperature=.9, model="text-davinci-003")

    # Wrapper for Llama-2-7B-Chat, Running Llama 2 on CPU

    #ì–‘ìí™”ëŠ” weightë¥¼ 16ë¹„íŠ¸ ë¶€ë™ ì†Œìˆ˜ì ì—ì„œ 8ë¹„íŠ¸ ì •ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ëª¨ë¸ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ, 
    #ë¦¬ì†ŒìŠ¤ê°€ ì œí•œëœ ì¥ì¹˜ì— íš¨ìœ¨ì ìœ¼ë¡œ ë°°í¬í•˜ê³  ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.

    #C TransformersëŠ” Llama, GPT4All-J, MPT ë° Falconê³¼ ê°™ì€ ì¸ê¸° ëª¨ë¸ ì¤‘ ë‹¤ì–‘í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì„ ì§€ì›í•©ë‹ˆë‹¤.

    #C TransformersëŠ” GGML ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ C/C++ë¡œ êµ¬í˜„ëœ ë³€í™˜ê¸° ëª¨ë¸ì— ëŒ€í•œ ë°”ì¸ë”©ì„ ì œê³µí•˜ëŠ” Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
    llm = CTransformers(model='models/llama-2-7b-chat.ggmlv3.q8_0.bin',  #https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main
                    model_type='llama',
                    config={'max_new_tokens': 256,
                            'temperature': 0.01})
    
    #PROMPT êµ¬ì¶•ì„ ìœ„í•œ í…œí”Œë¦¿
    template = """
    Write a email with {style} style and includes topic :{email_topic}.\n\nSender: {sender}\nRecipient: {recipient}
    \n\nEmail Text:
    
    """

    #final PROMPT ìƒì„±
    prompt = PromptTemplate(
    input_variables=["style","email_topic","sender","recipient"],
    template=template,)

  
    #LLMì„ ì´ìš©í•œ response ìƒì„±
    response=llm(prompt.format(email_topic=form_input, sender=email_sender, recipient=email_recipient, style=email_style))
    print(response)

    return response


st.set_page_config(page_title="Generate Emails",
                    page_icon='ğŸ“§',
                    layout='centered',
                    initial_sidebar_state='collapsed')
st.header("Generate Emails ğŸ“§")

form_input = st.text_area('Enter the email topic', height=275)

#Creating columns for the UI - To receive inputs from user
col1, col2, col3 = st.columns([10, 10, 5])
with col1:
    email_sender = st.text_input('Sender Name')
with col2:
    email_recipient = st.text_input('Recipient Name')
with col3:
    email_style = st.selectbox('Writing Style',
            ('Formal', 'Appreciating', 'Not Satisfied', 'Neutral'),
            index=0)

submit = st.button("Generate")

if submit:
    st.write(getLLMResponse(form_input, email_sender, email_recipient, email_style))
